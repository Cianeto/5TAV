Meu tema? 
No meu trabalho eu montei um modelo de reconhecimento de dígitos por voz.

O que eu utilizei? 
- Eu encontrei um dataset de 30 mil arquivos de áudio com duração de < 1 segundo, de pessoas diferentes pronunciando os dígitos.

- Biblioteca Tensorflow para a construção do modelo e Librosa para o tratamento do dado de entrada.

Como tratei o dataset para o modelo? 
Os arquivos de áudio são carregados usando a biblioteca librosa, na taxa de amostragem original.

Para deixar o dataset mais digerível, os dados de entrada que são .wav são convertidos em espectogramas "Mel", que diferem-se do espectrograma comum por terem as frequências convertidas para a escala de "Mel", que é uma transformação logarítmica aplicada aos componentes do domínio da frequência, cuja ideia principal é representar os componentes do som, dando importância maior aos que mais sensibilizam o ouvido humano.

Esse espectograma, por ser uma representação visual do arquivo de áudio, torna mais fácil a entrada na rede neural. O espectograma gerado é redimensionado para 128x128 pixels, que é a quantidade de neurônios de entrada.

Como foi construído o modelo? 

Foi utilizada uma rede neural convolucional (CNN), que é uma escolha comum para tarefas baseadas em imagens e espectrogramas.

- Camada de Entrada com o tamanho dos espectogramas redimensionados

- Duas camadas convolucionais com funções de ativação ReLU seguidas por camadas de max-pooling

- Uma camada de flatten para preparar os dados para as camadas totalmente conectadas.

- Uma camada densa oculta com ativação ReLU.

- Uma camada de saída com tantos neurônios quanto há classes (no nosso caso, 10: 0 até 9) e uma função de ativação softmax para produzir probabilidades de classe.

Me abstive de entender a matemática por de trás desses conceitos.

Como foi feito o treino?

O dataset foi dividido em 80% para o treino (reconfiguração dos pesos) e 20% para o teste(avaliação da acurácia), com o modelo iterando o dataset inteiro 50 vezes.

Os testes realizados alcançaram uma acurácia de 100% trigésima sexta (36) iteração (cada iteração passando por 10000 áudios .wav).

Demonstração 